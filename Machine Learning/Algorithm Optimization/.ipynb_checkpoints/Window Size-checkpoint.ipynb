{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas for managing datasets\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib for additional customization\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Seaborn for plotting and styling\n",
    "import seaborn as sns\n",
    "\n",
    "# Numpy, Statistics and Random for math\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import statistics\n",
    "import scipy.signal\n",
    "\n",
    "# Warnings to remove complex to real warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit Learn for Machine Learning\n",
    "import sklearn\n",
    "from sklearn import metrics \n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for i in range(0, 6):\n",
    "    data = pd.read_csv('Data\\\\'+str(i)+'.csv')\n",
    "    frames.append(data)    \n",
    "    data.to_csv('Data\\\\'+str(i)+'Labels.csv', sep=',', header=False, columns=['label'])\n",
    "combined = pd.concat(frames)\n",
    "combined.to_csv('Data\\Combined.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = []\n",
    "for i in range(0, 6):\n",
    "    windows.append(pd.read_csv('Data\\\\'+str(i)+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "def splitDataFrameIntoSmaller(df, chunkSize = 10000): \n",
    "    listOfDf = list()\n",
    "    numberChunks = len(df) // chunkSize + 1\n",
    "    for i in range(numberChunks):\n",
    "        listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])\n",
    "    return listOfDf\n",
    "\n",
    "def energy(array, wSize):\n",
    "    array = map(int, array)\n",
    "    fft = np.fft.fft(array)\n",
    "    sum = 0\n",
    "    for i in range(0, len(fft)):\n",
    "        sum = sum + (fft[i]*fft[i])\n",
    "    return float(sum)/wSize\n",
    "\n",
    "def correlation(x, y):\n",
    "    corr = np.corrcoef(x, y)\n",
    "    sum = 0\n",
    "    for i in range(0, len(corr)):\n",
    "        for j in range(0, len(corr[i])):\n",
    "            sum = sum + corr[i][j]\n",
    "    return sum/4\n",
    "\n",
    "def mean(x):\n",
    "    return np.mean(x, dtype=np.float64)\n",
    "\n",
    "#print correlation([3.12341325, 2.123123124,1.23123123, 1.231241241,3.31231231], [3.312412412, 2.13124124124, 2.31231231, 1.41241241, 2.31231233])\n",
    "\n",
    "print len(windows)\n",
    "features = []\n",
    "for i in range(0, len(windows)):\n",
    "    #print 'i'+str(i)\n",
    "    for j in range(9, 150, 6):\n",
    "        #print 'j'+str(j)\n",
    "        data = splitDataFrameIntoSmaller(windows[i], j)\n",
    "        #print len(data)\n",
    "        for k in range(0, len(data)-1):\n",
    "\n",
    "            ID = data[k]['participantID'].values[0]\n",
    "            windowSize = float(j)\n",
    "            gyro1 = map(float,data[k]['gyro1'])\n",
    "            gyro2 = map(float,data[k]['gyro2'])\n",
    "            gyro3 = map(float,data[k]['gyro3'])\n",
    "            accel1 = map(float,data[k]['accel1'])\n",
    "            accel2 = map(float,data[k]['accel2'])\n",
    "            accel3 = map(float,data[k]['accel3'])\n",
    "            label = data[k]['labelnum'].values[0]\n",
    "            \n",
    "            features.append([ID, windowSize, mean(gyro1), statistics.stdev(gyro1), energy(gyro1, j), \n",
    "                                        mean(gyro2), statistics.stdev(gyro2), energy(gyro2, j), \n",
    "                                        mean(gyro3), statistics.stdev(gyro3), energy(gyro3, j), \n",
    "                                        mean(accel1), statistics.stdev(accel1), energy(accel1, j), \n",
    "                                        mean(accel2), statistics.stdev(accel2), energy(accel2, j), \n",
    "                                        mean(accel3), statistics.stdev(accel3), energy(accel3, j), \n",
    "                                        correlation(gyro1,gyro2), correlation(gyro1,gyro3), \n",
    "                                        correlation(gyro1,accel1), correlation(gyro1,accel2), \n",
    "                                        correlation(gyro1,accel3), \n",
    "                                        correlation(gyro2,gyro3), correlation(gyro2,accel1),\n",
    "                                        correlation(gyro2,accel2), correlation(gyro2,accel3),\n",
    "                                        correlation(gyro3,accel1), correlation(gyro3,accel2),\n",
    "                                        correlation(gyro3,accel3),\n",
    "                                        correlation(accel1,accel2), correlation(accel1,accel2),\n",
    "                                        correlation(accel2,accel3), label])\n",
    "        #dataFrame.to_csv('Data\\\\'+str(i)+' '+str(j)+'.csv', sep=',', header=False)\n",
    "dataFrame = pd.DataFrame(data=features) \n",
    "dataFrame.columns = ['participantID','windowSize','mg1','stdevg1','energyg1','mg2','stdevg2','energyg2','mg3','stdevg3','energyg3','ma1','stdeva1','energya1','ma2','stdeva2','energya2','ma3','stdeva3','energya3','g1g2','g1g3','g1a1','g1a2','g1a3','g2g3','g2a1','g2a2','g2a3','g3a1','g3a2','g3a3','a1a2','a1a3','a2a3','label']\n",
    "dataFrame.to_csv('Data\\Windows.csv', sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 5]\n"
     ]
    }
   ],
   "source": [
    "items = rand.sample([0, 1, 2, 3, 4, 5], 3)\n",
    "print items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.6993708312548893: 1800, 0.7578678431237913: 8200, 0.70614144484897723: 4200, 0.76444003351376422: 5400, 0.71630815088621613: 7000, 0.69595066223786761: 3400, 0.71208990014960172: 9400, 0.72050849325237343: 8600, 0.71087671073490688: 9800, 0.73449841953164841: 1000, 0.70548886978976311: 1400, 0.72805253950704996: 600, 0.70058638575423615: 3000, 0.69524626575601089: 4600, 0.706225772549122: 6600, 0.69959329606258702: 2200, 0.71554647982077013: 5000, 0.70096146314303087: 3800, 0.71855032839014532: 7800, 0.72707199502410191: 5800, 0.72256508094507355: 9000, 0.71227630646873175: 7400, 0.69515952184518903: 2600, 0.72162768721946613: 6200}\n",
      "    windowSize  accuracy  participantID\n",
      "0          600  0.535652              2\n",
      "1          600  0.795152              1\n",
      "2          600  0.853353              5\n",
      "3         1000  0.580271              2\n",
      "4         1000  0.795724              1\n",
      "5         1000  0.827500              5\n",
      "6         1400  0.539919              2\n",
      "7         1400  0.797342              1\n",
      "8         1400  0.779206              5\n",
      "9         1800  0.539130              2\n",
      "10        1800  0.797721              1\n",
      "11        1800  0.761261              5\n",
      "12        2200  0.548936              2\n",
      "13        2200  0.796167              1\n",
      "14        2200  0.753676              5\n",
      "15        2600  0.547739              2\n",
      "16        2600  0.800000              1\n",
      "17        2600  0.737740              5\n",
      "18        3000  0.591837              2\n",
      "19        3000  0.798100              1\n",
      "20        3000  0.711823              5\n",
      "21        3400  0.587459              2\n",
      "22        3400  0.797844              1\n",
      "23        3400  0.702550              5\n",
      "24        3800  0.590406              2\n",
      "25        3800  0.798193              1\n",
      "26        3800  0.714286              5\n",
      "27        4200  0.593496              2\n",
      "28        4200  0.797342              1\n",
      "29        4200  0.727586              5\n",
      "..         ...       ...            ...\n",
      "42        6200  0.632530              2\n",
      "43        6200  0.799020              1\n",
      "44        6200  0.733333              5\n",
      "45        6600  0.632258              2\n",
      "46        6600  0.795812              1\n",
      "47        6600  0.690608              5\n",
      "48        7000  0.619048              2\n",
      "49        7000  0.798883              1\n",
      "50        7000  0.730994              5\n",
      "51        7400  0.640288              2\n",
      "52        7400  0.795322              1\n",
      "53        7400  0.701220              5\n",
      "54        7800  0.646617              2\n",
      "55        7800  0.801242              1\n",
      "56        7800  0.707792              5\n",
      "57        8200  0.738095              2\n",
      "58        8200  0.802632              1\n",
      "59        8200  0.732877              5\n",
      "60        8600  0.655462              2\n",
      "61        8600  0.795918              1\n",
      "62        8600  0.710145              5\n",
      "63        9000  0.640351              2\n",
      "64        9000  0.801418              1\n",
      "65        9000  0.725926              5\n",
      "66        9400  0.645455              2\n",
      "67        9400  0.798507              1\n",
      "68        9400  0.692308              5\n",
      "69        9800  0.634615              2\n",
      "70        9800  0.790698              1\n",
      "71        9800  0.707317              5\n",
      "\n",
      "[72 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "data = pd.read_csv('Data\\Windows.csv')\n",
    "data = clean_dataset(data)\n",
    "#print data.head()\n",
    "dataColumns = ['mg1','stdevg1','energyg1','mg2','stdevg2','energyg2','mg3','stdevg3','energyg3','ma1','stdeva1','energya1','ma2','stdeva2','energya2','ma3','stdeva3','energya3','g1g2','g1g3','g1a1','g1a2','g1a3','g2g3','g2a1','g2a2','g2a3','g3a1','g3a2','g3a3','a1a2','a1a3','a2a3']\n",
    "'''\n",
    "trainDataValues = data.query('(participantID==0 or participantID==1) and windowSize==9 and label!=1').filter(items=dataColumns)\n",
    "trainLabels = data.query('(participantID==0 or participantID==1) and windowSize==9 and label!=1').filter(items=['label'])\n",
    "testDataValues = data.query('participantID==3 and windowSize==9 and label!=1').filter(items=dataColumns)\n",
    "testLabels = data.query('participantID==3 and windowSize==9 and label!=1').filter(items=['label'])\n",
    "\n",
    "mnb = GaussianNB()\n",
    "mnb.fit(trainDataValues, trainLabels)\n",
    "predicted = mnb.predict(testDataValues)\n",
    "print(metrics.classification_report(testLabels, predicted))\n",
    "print(metrics.confusion_matrix(testLabels, predicted))\n",
    "'''\n",
    "accuracy = {}\n",
    "matrix = []\n",
    "chart = []\n",
    "for i in range(9, 150, 6):\n",
    "    mean = []\n",
    "    windowSize = (i/3)*200\n",
    "    for j in range(0, len(items)):\n",
    "        string = '('\n",
    "        string2 = ''\n",
    "        for k in range(0, len(items)):\n",
    "            if k != j:\n",
    "                string += 'participantID=='+str(items[k])+' or '\n",
    "                #if k < (len(items)-1):\n",
    "                #    string += ' or '\n",
    "            else:\n",
    "                string2 += 'participantID=='+str(items[k])\n",
    "        \n",
    "        string = string[:-3] + ') and windowSize=='+str(i)+' and label!=1'\n",
    "        string2 += ' and windowSize=='+str(i)+' and label!=1'\n",
    "        trainDataValues = data.query(string).filter(items=dataColumns)\n",
    "        trainLabels = data.query(string).filter(items=['label'])\n",
    "        testDataValues = data.query(string2).filter(items=dataColumns)\n",
    "        testLabels = data.query(string2).filter(items=['label'])\n",
    "\n",
    "        mnb = GaussianNB()\n",
    "        mnb.fit(trainDataValues, trainLabels)\n",
    "        predicted = mnb.predict(testDataValues)\n",
    "        fold = metrics.accuracy_score(testLabels,predicted)\n",
    "        mean.append(fold)\n",
    "        matrix.append([windowSize,fold,items[j]])\n",
    "        #accuracy.update({metrics.accuracy_score(testLabels,predicted):i})\n",
    "    chart.append([windowSize,np.mean(mean)])\n",
    "    accuracy.update({np.mean(mean):windowSize})\n",
    "matrix = pd.DataFrame(matrix, columns=['windowSize','accuracy','participantID'])\n",
    "matrix.to_csv('Data\\windowResults.csv', sep=',', index=False)\n",
    "print accuracy\n",
    "print matrix\n",
    "chart = pd.DataFrame(chart, columns=['windowSize','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
